#argentina, bolivia,colombia, dominican republic, panama
library(data.table)
library(stringr)
#regions
#Set root directory
#root<- r"(C:\Users\AP03054557\OneDrive\Edmundo-ITESM\3.Proyectos\42. LAC Decarbonization\VA Analysis\)"
root<- r"(/Users/nidhi/OneDrive - RAND Corporation/LAC Decarb QA Simulations/)"
setwd(root)
#load emissions targets
te_all<-read.csv(paste0(root,"target_emissions.csv"))
#ouputfile
#output.file<-"backup_new.csv"
output.file<-list.files(pattern = 'sisepuede_results_sisepuede_run_')
model_output_file_name<-output.file
data_all<-read.csv(paste0(root,output.file))
rall <- unique(data_all$region)
#source rescale function
source(paste0(root,"rescale_function.r"))
#z<-1
#rescale(z,rall,data_all,te_all)
for( z in 1:length(rall))
{
rescale(z,rall,data_all,te_all)
}
for( z in 13:length(rall))
{
rescale(z,rall,data_all,te_all)
}
#Integrate all the files
files <- list.files(paste0(root,"Nations/"),pattern =".csv")
data <- list()
for (i  in 1:length(files))
{
pivot <- read.csv(paste0(root,"Nations/",files[i]))
pivot$X<-NULL
data <- append(data,list(pivot))
}
data <- do.call("rbind",data)
tv1_all <- subset(colnames(data),grepl("co2e_",colnames(data))==TRUE)
data$emission_co2e_TOTAL <- rowSums(data[,tv1_all])
data$Index<-paste0(data$primary_id,"_",data$region)
test<-aggregate(list(Max_CO2e=data$emission_co2e_TOTAL),list(Index=data$Index),max)
summary(test)
test<-subset(test,Max_CO2e>1e6)
dim(data)
data<-subset(data,!(Index%in%unique(test$Index)))
dim(data)
data$Index<-NULL
#how many runs we have per country
ids<-unique(data$primary_id)
rall<-unique(data$region)
out<-list()
for (i in 1:length(rall))
{
#i<-1
pivot<-data.frame(ids=ids)
pivot[,rall[i]]<-0
checks<-pivot$ids%in%unique(data$primary_id[data$region==rall[i]])
checks <- ifelse(checks==TRUE,1,0)
pivot[,rall[i]]<- checks
out<-append(out,list(pivot))
}
write.csv(data,paste0(root,"out/",str_replace(model_output_file_name, '.csv', ''), "_scaled.csv"),row.names=FALSE)
#-------------SET WORKING DIRECTORY AND PATHS----------
setwd('~/Desktop/LAC_Decarb_Git/sisepuede_costs_benefits/Main/')
#Paths to data files
path_to_model_results<-'/Users/nidhi/OneDrive - RAND Corporation/LAC Decarb QA Simulations/sisepuede_summary_results_run_sisepuede_run_2023-09-28T11;36;58.322719/'
data_filename<-paste0(path_to_model_results,
list.files(path=path_to_model_results,
pattern = glob2rx('sisepuede_results_sisepuede_run_*_scaled.csv'))) #path to model output runs
primary_filename<-paste0(path_to_model_results, 'ATTRIBUTE_PRIMARY.csv') #path to model output primary filename
strategy_filename<-paste0(path_to_model_results, 'ATTRIBUTE_STRATEGY.csv') #path to model output strategy filename
cb_output_filename<-paste0(path_to_model_results,'cost_benefit_results.csv') #path to write results
net_benefit_ghg_output_filename<-paste0(path_to_model_results,'net_benefit_net_ghg.csv') #path to write results
cb_futures_output_filename<-paste0(path_to_model_results,'cost_benefits_in_futures.csv') #path to write results
trimmed_data_filename<-paste0(path_to_model_results, 'sisepuede_results_TRIMMED_LONG.csv') #path to trimmed data for Tableau
#-------------SOURCE LIBRARIES AND CODE-----
source('cb_config.R')
source('cb_utilities.R')
source('cb_strategy_specific_functions.R')
source('general_ssp_utilities.R')
#-------------READ THE DATA-----------------
output.file<-read.csv(data_filename)
#-------------PREPARE THE DATA--------------
#Read data
data<-output.file
#Merge model output with strategy attributes (mainly the strategy_code)
run_attributes<-ssp_merge_run_attributes(primary_filename, strategy_filename)
merged_data<-merge(run_attributes[,c('primary_id', 'strategy_code', 'future_id')], data, by=c('primary_id'), x.all=TRUE)
data<-merged_data
#clean the data of furnace gas and crude
temp_data_cols<-colnames(data)
cols_to_keep<-temp_data_cols[!grepl('totalvalue.*furnace_gas', temp_data_cols)]
cols_to_keep<-cols_to_keep[!grepl(glob2rx('totalvalue_*_fuel_consumed_*_fuel_crude'), cols_to_keep)]
data = subset(data, select = cols_to_keep )
#add calculation of total TLUs to data
tlu_conversions<-read.csv('../strategy_specific_cb_files/lvst_tlu_conversions.csv')
pop_livestock<-data[, c(SSP_GLOBAL_SIMULATION_IDENTIFIERS, 'future_id', colnames(data)[grep('pop_lvst', colnames(data))])]
pop_livestock<-melt(pop_livestock, id.vars=c('primary_id', 'time_period', 'region', 'strategy_code', 'future_id'))
pop_livestock<-merge(pop_livestock, tlu_conversions, by='variable')
pop_livestock$total_tlu<-pop_livestock$value * pop_livestock$TLU
pop_livestock_summarized<-pop_livestock %>%
group_by(primary_id, time_period, region, strategy_code, future_id) %>% #c('primary_id', 'time_period', 'region', 'strategy_code')) %>%
summarise(lvst_total_tlu= sum(total_tlu))
data<-merge(data, pop_livestock_summarized, by=c('primary_id', 'time_period', 'region', 'strategy_code', 'future_id'))
#replace any lagging references to "PFLO:SOCIOTECHNICAL" with "PFLO:CHANGE_CONSUMPTION"
data$strategy_code[data$strategy_code=='PFLO:SOCIOTECHNICAL']<-'PFLO:CHANGE_CONSUMPTION'
SSP_GLOBAL_list_of_strategies<-unique(data$strategy_code)
SSP_GLOBAL_list_of_variables<-setdiff(colnames(data), SSP_GLOBAL_SIMULATION_IDENTIFIERS)
#-------------PRODUCE A COPY OF TRIMMED INPUT DATA FOR TABLEAU-------------------
#create a column of outputs
cols_to_grep<-c(
'primary_id',
'\\bregion\\b',
'time_period',
'future_id',
#    'area_agrc',
'area_lndu',
'demand_agrc',
'demand_lvst',
'yield_agrc',
'pop_lvst',
#  'exportsadj_lvst',
#  'exportsadj_agrc',
#  'emission_co2e_subsector_total',
'emission_co2e',
#  'lndu_conversion',
'totalvalue_enfu_fuel_consumed',
glob2rx('energy_consumption_*_total'),
'energy_demand_enfu_subsector_total_pj_',
'energy_demand_enfu_total_fuel_',
'nemomod_entc_annual_production_by_technology',
'qty_waso'
, 'trns'
)
trimmed_data_long<-ssp_trim_reshape(data, cols_to_grep)
write.csv(trimmed_data_long, trimmed_data_filename)
